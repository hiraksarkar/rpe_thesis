\chapter{Introduction}
%highlight how biological analysis is driven by 
\note{The} advent of high throughput sequencing has revolutionized the \st{field of} analysis of biological data. The enormous scale of technological improvement has doubled the capacity of DNA sequencing each year \citep{reuter2015high}. Be it the study of cellular processes, response of cellular pathways to drugs or transcriptional regulation, \note{many different types of biological analysis are} now highly depend on an established pipeline of creating the experimental set up, choosing a suitable sequencing technology \note{(sometimes designing one if needed)} and sequencing \note{a series of} samples. The volume of data and speed of \st{rapid} sequencing \note{have widened} the scope of rigorous statistical study and \note{led to the} application of sophisticated techniques from data science, \note{e.g. as} described in \citep{schatz2015biological}, in order to \note{extract} biological insights from \note{vast volumes of sequencing data}. High throughput sequencing technology also enables scientists to design \note{protocols} to serve particular applications, for example RNA-seq \citep{mortazavi2008mapping} and Ribo-seq \citep{gerashchenko2012genome} \note{are} designed to measure the level of \note{mRNA and the rate of translation, respectively}.  \note{The} frequency of protein binding is revealed by ChiP-seq \citep{zhang2008model} technology, and nascent RNA transcription rate is measured by GRO-seq and PRO-seq \citep{core2008nascent} \note{assays}. Furthermore, recent single-cell technologies \note{have enabled the probing of transcript expression profiles} at the level of individual cells, which reveal\note{s the} heterogeneity of different types of cells (i.e. different tissue types etc.). 

In this \note{document} we \note{will} mostly \note{focus on} RNA-seq data. Given the availability and low cost of production, RNA-seq has become one of the standard ways to measure mRNA abundance in a cell \note{\textbf{cite something about prevalence of RNA-seq}}. It has wide application including {\it de novo} transcriptome assembly, estimating isoform expression, and identifying novel transcripts and measuring differential expression under various conditions, like response to changing stimuli~\citep{Stubben2014} and disease states~\citep{diseaseDGE}.  \note{Given the vast quantity of data often gathered to address such questions, studying these problems also requires computationally efficient methods capable of scaling with the experimental size}. A number of algorithms by \citep{langmead2009ultrafast}, \citep{tophat}, \citep{mortazavi2008mapping} have been designed to analyse the sequencing data from RNA-seq experiments \note{\textbf{I think a bit more detail is needed here.  What challgenges did these algorithms solve?  Why did you choose these as representative? etc.}}. The \st{formal} \note{widely-used} RNA-seq data analysis pipeline, \note{consists} of three steps, first the single-end or the paired-end reads from the experiment are mapped or aligned to the reference transcriptome \note{\textbf{or genome?}}. In case the reference transcriptome is not present, \note{either} a {\it de novo} \note{or reference-guided} assembly step is required to get an estimate of the contigs \note{present in the sample} \note{\textbf{(you haven't defined contig yet)}}. In the second step, abundance estimation is \note{performed}. \note{Often, this is done by counting the reads that overlap an annotated or assembled transcript or gene, but mounting evidence has demonstrated that resolving the multi-mapping ambiguities by performing inference in an appropriate probabilistic model \citep{pachter2011models} yields considerably more accurate abundances}. After these two steps, the \note{resulting estimates}, i.e. \note{the quantification results} are used to find out the expression levels of the genes \note{\textbf{(the quantification results are the expression levels, right?)}}.  As described above, \note{the variables of interest in the experimental design are used in conjunction with the quantification results to perform differential expression analysis}.
\note{This allows one to study how the abundance of genes or transcripts changes with experimental factors; for example, to study how certain genes are down-regulated or up-regulated in response to a particular drug}. 

It is important to note that RNA-seq experiments generate ``steady state'' \note{\textbf{(you should define what you mean here, or reference a description in the appendix, etc.)}} fragments from spliced transcripts, which makes the alignment step inherently difficult. A gene can \note{express} multiple isoforms, \note{even} in \note{a single} experiment. Isoforms from \note{the} same gene often share exons, which enables the generation of read sequences that, when mapped to transcriptome would naturally align with multiple transcripts at the same time. In this thesis we would propose a novel way to represent the data from a sequencing experiment by encoding the mapping information in terms of {\it equivalence classes}. Furthermore we would show two application where this representation can take aid to design robust and accurate algorithms. 

The first application aims to refine the {\it de novo} transcriptome assemblies, \note{resulting} from different the state-of-the-art assemblers. \note{Specifically, we design a method to cluster \emph{de novo} assembled contigs into putative genes based on shared, expressed sequence.  This enables ``gene-level'' analysis of \emph{de novo} transcriptome assemblies, mitigating the effect of assembly errors on quantification and differential analysis.}  Despite \note{the} advanced algorithms used in assemblers, the reconstructed transcriptome often contains several errors including hybrid assembly where there are contigs from several gene families are clustered together \note{\textbf{(using the term ``clustered'' here is a bit confusing, since we do a clustering)}}, chimeric contigs (\note{the spurious assembly of different underlying transcripts into a a single contig}), spurious insertions and local mis-assemblies \citep{transrate}. Though improved computational methods can reduce the prevalence of such errors, the data itself is often insufficient to guarantee deterministic recovery of all expressed transcripts.  The fractured and incomplete nature of such \denovo assemblies can confound downstream analysis. We have \note{devised a method} that \note{exploits the} above mentioned equivalence classes \note{to pose and solve a graph clustering problem, which allows us to cluster even fractured transcriptome assemblies into clusters representing putative genes}. We implemented this concept as a tool \rapclust, which is explained in Chapter 2.

The second application \note{we explore} is to exploit the idea of equivalence classes to \note{derive} a succinct representation of raw read sequences. From studying the mapping patter of RNA-seq data, we have observed that \note{a} substantial \note{fraction} of reads map to a limited number of transcripts which are highly expressed in that sample. \note{Even when multimapping is prevalent, reads tend to multimap between transcripts in consistent and repeated patterns, which can be exploited for the purposes of efficient compression}. Transcripts \note{are often covered by multimappint reads in a series of} discontinuous region of highly abundant sequences, characterized as \islands. We design \note{a} semi-reference-based compression tool \note{\textbf{(describe what semi-reference-based is, and why it is interesting)}}, \quark, after extracting the set of islands by \note{mapping} raw RNA-seq reads to the reference transcriptome using \rapmap. Chapter 3 is devoted for detail explanation of \quark. 

% more about equivalence classes




%For example,~\citet{corset} argue that the large number of contigs that often result from \denovo transcriptome assembly can greatly reduce the statistical power of differential expression analysis.      


\section{Alignment and Mapping}
Ambiguous mapping has made the problem of quantification extremely challenging for RNA-seq data. \citet{salzman2011statistical} and \citet{pachter2011models} described useful models that can be used for quantification under multi-mapping. \citet{sailfish} discovered the fact that a costly alignment is not really required for the purpose of quantification, \note{related ideas that bypassed traditional notions of alignment were} later used by \citet{kallisto} and \citet{salmon}. On the other hand \citet{rapmap},  proved that a stand alone exclusive mapper can be useful for multiple applications \note{\textbf{(we did nothing with metagenomics yet, but you can mention \rapclust here)}}. What all the aforementioned work shares is the concept of putting similar reads together. Before we discuss the evolution of putting similar reads together in equivalence classes, let us formally define the mathematical framework of \note{the} sequence mapping/alignment paradigm. 

\subsection{Mathematical framework for nucleotide sequence matching}
Given a \note{set of characters from an alphabet} $\Sigma$, \note{of size $\left|\Sigma\right$}, and two non-empty sequences $x,y \in \Sigma^+$, \note{an alignment} can be defined as a function $f : x \rightarrow \Sigma \cup \{-\}$, where, $``-"$ is a character to denote a gap has been introduced. Often there is a cost metric $d$ associated with the function $f$, defined as follows, 
\begin{align}
    d(x_i,y_j) &= 0,\text{ if } f(x_i) = y_j \\
    &= \text{mismatch penalty},\text{ if } f(x_i) \neq y_j \\
    &= \text{gap penalty},\text{ if } f(x_i) = ``-" 
\end{align}

\note{\textbf{(If you're going to give a formal definition, I think you need to provide a bit more detail here, and should also cite some of the original / early work covering the sequence alignment problem)}}.

The goal of most alignment algorithms \citep{Li2010} \note{is to find alignments between the query and reference sequence to minimize the penalty of alignment, or to report if no alignment below a given penalty threshold exists}. 

For mapping, as mentioned above, the mismatch or gaps are not considered as part of matching function. It is shown by \citet{salmon},\citet{kallisto} and \citet{rapmap} that for \note{certain} downstream analyses, it is adequate to find out the location where read maps and the target sequence rather than full alignment information. These approaches often define mapping on the basis of a threshold. It is to be noted, although \citet{sailfish} did not map the reads explicitly, it introduced the concept \note{eliding the traditional read alignment step} which, in turn, inspired the batch of mapper dependent tools that followed it.

\subsection{Mapping in framework of RNA-seq}
Although at conceptual level RNA-seq mapping is not very different from alignment described above, but it would be worthwhile to define if formally as, these definitions are used through out the rest of the report.

Given a set of $M$ transcripts (or transcriptome) $T = \{t_1,t_2,\ldots,t_M\}$, where $t_i$ represents the nucleotide sequence for transcript $i$, likewise  $R = \{r_1,r_2,\ldots,r_N\}$ denotes a set of read sequences (might be paired end or single end), we can define the task of mapping as \note{finding} a function $\mathcal{Q} : {T,R} \rightarrow \mathcal{P}$, where $\mathcal{P}$ is a set of tuples. $\mathcal{P} = \{(r_i,t_j,p_k) : r_i \in R, t_i \in T, p_k \in \mathbb{N}\}$. The presence of tuple $(r_i,t_j,p_k)$ represents the fact that read $r_i$ is mapped to transcript $t_j$ at position $p_k$ \note{\textbf{(I would add orientation here)}}. The concept of equivalence classes, described in this report, are derived from $\mathcal{P}$.  

\section{Equivalence class as a concept}

The concept of grouping similar reads together is not new concept. It has been mentioned several times in the literature either for improving multiple alignments or constructing a consensus. Although it is hard to \note{provide a} full chronological account for the exact mention of such a concept in the context of computational biology, we would try to cover some important papers that implicitly made use of such a concept. 

\note{\textbf{Here is some text I wrote for the salmon manuscript describing the history of equivalence classes in RNA-seq explicitly.  Obviously, you shouldn't take any of this verbatim, but feel free to use it for inspiration below if you want to add anything:

Collapsing fragments into equivalence classes is a
well-established idea in the transcript quantification literature,
and numerous different notions of equivalence classes have
been previously introduced, and shown to greatly reduce the time
required to perform iterative optimization such as that described
in XXX. For example, Salzman et al. (2011) first introduced the notion of factorizing the likelihood function to speed up inference by collapsing fragments that align to the same exons or exon junctions (as determined by a provided annotation) into equivalence classes. Simlarly, Nicolae et al. (2011) used equivalence classes over fragments to reduce memory usage and speed upinference --- they define as equivalent any pair of fragments that align to the same set of transcripts and whose compatibility weights (i.e. conditional probabilities) with respect to those transcripts are proportional.  Patro et al.(2014) define equivalence classes over k-mers, treating as equivalent any k-mers that appear in the same set of transcripts at the same frequency, and use this factorization of the likelihood function to speed up optimization.  Bray et al. (2015) define equivalence classes over fragments, and define as equivalent any fragments that pseuoalign to the same set of transcripts --- this is similar to the notion adopted by Nicolae et al., except that no restriction is placed on the proportionality of compatibilityweights (since these are not computed).}}


\citet{pop2004} proposed the concept of grouping highly overlapping reads in the context of genome assembly. \citet{Salmela2011} considered the idea of grouping reads together on the basis of k-mer matches. \citet{isoem} made the idea of equivalence classes explicit to solve expression estimation problem of gene isoforms. They developed a line sweep algorithm to detect read-isoform compatibility on the basis of sequence similarity. As mentioned before \citep{sailfish} elaborated the idea to implement a k-mer based grouping of the reads. Recent methods \citep{kallisto},\citep{salmon},\citep{rapmap} have implemented it more explicitly. 

Given this back ground on progression of development we can now formally define the idea of grouping reads and equivalence classes in the context of the current report.  

\subsection{Definition of equivalence classes}
\label{subsec:gen_equiv_classes}
We define an equivalence relation over reads, based on the set of transcripts to which they map.  The set of reads related under this definition constitutes a read equivalence class. Let $\mathcal{M}\left(r_i\right)$ be the set of transcripts to which read $r_i$ maps, and let $\mathcal{M}\left(r_j\right)$ be the set of transcripts to which read $r_j$ maps.  We say that $r_i \sim r_j$ if and only if $\mathcal{M}\left(r_i\right) = \mathcal{M}\left(r_j\right)$. Consequently, a read equivalence class is a set of reads such that, for every pair $r_i$ and $r_j$ in the class, $r_i \sim r_j$. An equivalence class can be uniquely labeled based on the set of transcripts to which the reads contained in this class map.  We define the label of equivalence class $\eqclass{r_i} = \{ r_j \in R \mid r_j \sim r_i\}$ as $\eqlabel{\eqclass{r_i}}$.  It is important to remember that, though the label consists of transcript names, the equivalence relation itself is defined over sequenced fragments and not transcripts. Finally, in addition to a label, we denote the count of each equivalence class $C_i$ by $\eqcount{C_i}$; this is simply the number of equivalent fragments in $C_i$.


Another interesting way to look at function $\mathcal{M}$ is to consider \note{it's output on a particular set of fragments as a binary matrix}. As shown in (1.4) a \note{binary} matrix can represent the read to transcript \note{mapping function}. After rearranging the rows we obtain $\mathcal{M'}$. Three equivalence classes can be extracted from here, $\{t_1,t_2,t_4\}, \{t_1\}$ and $\{t_1,t_4\}$. 

\begin{align}
  \mathcal{M}=\kbordermatrix{%
      & t_1 & t_2 & t_3 & t_4 \\
    r_1 & 1 & 1 & 0 & 1 \\
    r_2 & 1 & 0 & 0 & 0 \\
    r_3 & 1 & 1 & 0 & 1 \\
    r_4 & 1 & 0 & 0 & 0 \\
    r_5 & 1 & 1 & 0 & 1 \\
    r_6 & 1 & 0 & 0 & 1 \\
  }  &&
  \mathcal{M'}=\kbordermatrix{%
      & t_1 & t_2 & t_3 & t_4 \\
    r_1 & 1 & 1 & 0 & 1 \\
    r_3 & 1 & 1 & 0 & 1 \\
    r_5 & 1 & 1 & 0 & 1 \\
    \hline
    r_2 & 1 & 0 & 0 & 0 \\
    r_4 & 1 & 0 & 0 & 0 \\
    \hline
    r_6 & 1 & 0 & 0 & 1 \\
  }
\end{align}
 


%\section{}

