\chapter[\texttt{Quark}]{Clustering of \denovo transcriptome using equivalence classes\footnote{This is a joint work with Avi Srivastava, Laraib Malik and Rob Patro}}

Despite the advanced techniques employed by many modern \denovo transcriptome assemblers, the resulting assemblies often contain a large number of contigs which do not represent full-length transcripts.  These incomplete contigs may result from fractured assemblies, incomplete assemblies due to lack of coverage, errant assembly of chimeric transcripts, or a host of other errors~\cite{transrate}.  Though improved computational methods can reduce the prevalence of such errors, the data itself is often insufficient to guarantee deterministic recovery of all expressed transcripts.  The fractured and incomplete nature of such \denovo assemblies can confound downstream analysis.  For example,~\citet{corset} argue that the large number of contigs that often result from \denovo transcriptome assembly can greatly reduce the statistical power of differential expression analysis.  This results, in part, from the need to correct for testing the many additional hypotheses that arise from considering the large number of assembled contigs (which is likely much greater than the actual number of transcripts expressed in the sample).  Moreover, the sequence-similar contigs generated by \denovo assemblers typically result in a high fraction of ambiguous, multi-mapping reads.  This ambiguity is challenging to resolve, but must be accounted for when performing differential expression analysis at the contig level.

\begin{figure}[!ht]
\includegraphics[width=0.6\textwidth]{Figures/overview}
\centering
\caption{\label{fig:overview}An overview of the \rapclust pipeline. Fragment equivalence classes are computed using \qm, and these classes are used for both contig-level expression quantification and generation of the \ambiggraph. The \ambiggraph is partitioned using \mcl.  The resulting clusters can then be used for downstream analysis (e.g. differential expression).}
\end{figure}

Common pipelines for studying differential gene expression across experimental conditions first align the RNA-seq reads back to the assembled contigs.  Then, they use transcript-level expression estimation tools, such as RSEM~\citep{rsem}, to account for the high degree of multi-mapping ambiguity that results from the substantial sequence similarity between related contigs. To further improve expression estimates, contigs that have high similarity (e.g. that are very sequence-similar or that have many overlapping reads aligning between them) are clustered together as putative transcripts or contigs of the same gene. Statistical methods, such as those discussed in~\cite{kvam, soneson2013comparison}, are then used to identify contigs (or clusters of contigs) that are likely to be differentially expressed across conditions. Clustering of contigs into putative genes can be a crucial step in this analysis, since performing differential expression analysis at the level of clusters reduces the multiple hypothesis testing burden, which can be high in \denovo transcriptomes, owing to the potentially large number of assembled contigs.  Additionally, aggregating contigs into such groups can improve the robustness of expression estimation and hence the accuracy of differential expression analysis.  We note that, if one requires transcript-level differential expression, such a clustering procedure may not always be useful.  However, for many analyses, it is beneficial.

Although clustering may help improve the accuracy of differential expression results, it should be designed to account for the multiple sources of sequence similarity that appear in the assembly.  For example, paralogs should ideally be placed in separate clusters, while isoforms of the same gene should be co-clustered.  The effects of different clustering approaches in the context of analyzing \denovo transcriptomes has previously been explored in depth, e.g. by~\citet{corset}, which largely inspired the current work. Unfortunately, the approaches tend either to have high computational requirements (mainly due to their need to align $10$s or $100$s of millions of reads back to the assembly), or can yield clusters that may poorly reflect the true relationship between contigs and genes~\citep{cdhit}.  In this paper, we present \rapclust, a tool for clustering contigs in \denovo transcriptome assemblies.  \rapclust achieves comparable accuracy to state-of-the-art transcriptome clustering methods, while being much faster. \rapclust works in conjunction with the \sailfish tool, which is already capable of quickly and accurately producing contig-level abundance estimates.  It uses the fragment equivalence classes computed by \sailfish to derive accurate and biologically meaningful clusters at only a marginal extra cost, beyond what is required for quantification.

An overview of the \rapclust pipeline is given in Figure \ref{fig:overview}. \rapclust requires only a transcriptome assembly, the raw sequencing reads, and a description of the experimental design; it yields an accurate contig clustering, along with both contig and cluster-level expression estimates. \rapclust is agnostic to the choice of the underlying \denovo assembler, and can be used with popular tools such as Trinity~\cite{trinity} or Oases~\cite{oases}. \Qm, a recently introduced~\citep{rapmap} and fast alternative to read alignment, is used to map the reads to the assembled contigs. The multi-mapping structure of the sequencing reads with respect to the transcriptome is encoded in the form of {\it fragment equivalence classes}, as discussed in~\ref{subsec:quasimapping_equiv_classes}. These equivalence classes induce a \ambiggraph as detailed in~\ref{subsec:ambig_graph} (the notion of the fragment ambiguity graph has previously proven useful e.g. in the context of re-estimating transcript abundances after updates to an annotation~\citep{reexpress}). After some post-processing, the resulting graph is clustered using \mcl~\citep{mcl}. The computed clusters represent a putative contig-to-gene mapping, which can then be used to aggregate the contig-level expression estimates derived by \sailfish.  These cluster-level expression estimates can then be used for downstream analyses like differential expression testing.


\section{Methods}
\label{sec:methods}

In this work, we make explicit the connection between the successful approach of \denovo transcriptome clustering presented in~\cite{corset}, and the concept of equivalence classes over fragments that has enabled, in part, a new class of ultra-fast methods for transcript-level quantification from RNA-seq data~\cite{sailfish, salmon, kallisto}.  The notion of fragment equivalence classes, as a means of factorizing the likelihood function used in transcript-level quantification, was originally introduced by~\citet{isoem} and~\citet{mmseq} (though a related factorization was used somewhat earlier by~\citet{jiang}). Substantial speed improvements were obtained when traditional alignment of fragments was replaced with much faster procedures like k-mer counting~\citep{sailfish}, lightweight-alignment~\citep{salmon}, pseudoalignment~\citep{kallisto} and \qm~\citep{rapmap}.  All of the ultra-fast transcript quantification tools mentioned above use these fast alternatives to alignment together with the notion of fragment equivalence classes. In our current work, by drawing on this connection and focusing on the rich information exposed by fragment equivalence classes, we frame the transcript clustering problem in the context of the \ambiguitygraph induced by these equivalence classes. This allows for the rapid clustering of contigs, on the basis of both sequence and expression similarity, using only small intermediate space.

\subsection{Computing Equivalence Classes via Quasi-mapping}
\label{subsec:quasimapping_equiv_classes}

The concept of \qm, which provides information about the transcripts, positions and orientations from which a fragment has possibly originated, but not the base-to-base alignment by which the fragment corresponds to the transcript, has recently been introduced in~\citet{rapmap}. There, it is suggested that \qm may be adopted as a much-faster alternative to fragment alignment when the base-to-base alignments are not required for the task being performed. \citeauthor{rapmap} describe an efficient implementation \qm in the tool \rapmap, and demonstrate how integrating \qm in the \sailfish software for transcript-level quantification led to considerable improvements in accuracy and speed. Here, we rely on \qm to allow for very fast and accurate determination of fragment equivalence classes, which is crucial to the approach we adopt below. We note that, though \qm does not compute a nucleotide-level alignment, it is sensitive to even small differences in related reference sequences.  Thus, it can accurately map fragments to e.g. the appropriate paralog, even if the fragment contains only a single SNP differentiating the alternative reference sequences.  We refer the reader to~\citep{rapmap} for details of the \qm concept and the particular algorithm used by \rapmap.

% Describe the equivalence classes
We use the same definition of equivalence classes defined in \ref{subsec:gen_equiv_classes} but in the context of fragments instead of reads.
Just as the case of reads we define an equivalence relation over fragments, based on the set of transcripts to which they map.  The set of fragments related under this definition constitutes a fragment equivalence class.  Let $\mathcal{M}\left(f_i\right)$ be the set of transcripts to which fragment $f_i$ maps, and let $\mathcal{M}\left(f_j\right)$ be the set of transcripts to which fragment $f_j$ maps.  We say that $f_i \sim f_j$ if and only if $\mathcal{M}\left(f_i\right) = \mathcal{M}\left(f_j\right)$. Consequently, a fragment equivalence class is a set of fragments such that, for every pair $f_i$ and $f_j$ in the class, $f_i \sim f_j$. An equivalence class can be uniquely labeled based on the set of transcripts to which the fragments contained in this class map.  We define the label of equivalence class $\eqclass{f_i} = \{ f_j \in \mathcal{F} \mid f_j \sim f_i\}$ as $\eqlabel{\eqclass{f_i}}$.  It is important to remember that, though the label consists of transcript names, the equivalence relation itself is defined over sequenced fragments and not transcripts.  Finally, in addition to a label, we denote the count of each equivalence class $C_i$ by $\eqcount{C_i}$; this is simply the number of equivalent fragments in $C_i$.

\subsection{Quantification and Graph Determination}
\label{subsec:ambig_graph}

The fragment equivalence classes, as described above, are already computed internally by \\ \sailfish \citep{sailfish}. We have modified \sailfish to write these equivalence classes to a file once quantification is complete (this behavior is enabled with the \texttt{--dumpEq} flag).  This yields, for each \textit{sample}, a collection of equivalence classes, along with their associated labels and counts. To construct the complete \ambiggraph of the \textit{experiment} we need to aggregate these equivalence classes over all of the processed samples. In fact, this aggregation is relatively simple since the labels of fragment equivalence classes are deterministic and stable across samples (i.e. they depend only on the underlying transcriptome). We generate a single collection $\mathcal{C}$ of equivalence classes by merging the classes $\mathcal{C}_1, \dots, \mathcal{C}_M$, from all samples, where $M$ is the number of samples. Here, $\mathcal{C}$ contains the union of equivalence classes from $\mathcal{C}_1, \dots, \mathcal{C}_M$, and classes that appear in more than one sample of $\mathcal{C}_1, \dots, \mathcal{C}_M$ simply have their respective read count summed.  The time and space requirement for this aggregation algorithm is linear in the size of input.

% Now, define the graph in terms of the classes
For a given experiment, the collection $\mathcal{C} = \{C_1,C_2,\ldots,C_k\}$ of equivalence classes induces a weighted, undirected, \ambiggraph $G = \left(V, E\right)$.  Here, $V = T$, where $T$ is the set of transcripts in the original transcriptome --- and $E = \{ \{t_i, t_j\} \mid \exists\; C_\ell \in \mathcal{C} \text{ where } \{t_i, t_j\} \subseteq \eqlabel{C_\ell}\}$ --- that is $t_i$ and $t_j$ are connected by an edge if and only if they both appear in the label of at least one equivalence class.  For a given edge $\{t_i, t_j\}$, its weight is given by $w\left(t_i, t_j\right) = \nicefrac{N_{ij}}{\min\left(N_i, N_j\right)}$, where
    %
    \[
    N_{ij} = 
    \sum_{\substack{C_\ell \in \mathcal{C} \mid \\ \{t_i, t_j\} \subseteq \eqlabel{C_\ell}}} \eqcount{C_\ell}
        ,\, N_i = \sum_{\substack{C_\ell \in \mathcal{C} \mid \\ t_i \in \eqlabel{C_\ell}}} \eqcount{C_\ell} \text{ and }
    N_j = \sum_{\substack{C_\ell \in \mathcal{C} \mid \\ t_j \in \eqlabel{C_\ell}}} \eqcount{C_\ell}
    \]

While the samples we process from a \denovo RNA-seq experiment may contain $10$s to $100$s of millions of fragments, the number of nodes in $G$ is determined by the number of contigs.  Further, the number of edges is bounded by the \textit{complexity} of the transcriptome (i.e. the degree of alternative splicing and paralogy in the underlying transcriptome), and, therefore, mostly independent of the number of fragments processed. 

For the transcriptomes and samples we analyze in this paper, the number of equivalence classes never rises above a few hundred thousand, and is typically orders of magnitude smaller than the number of fragments (see~\ref{tab:data} for the number of equivalence classes in the different data sets).  Thus, if the equivalence classes can be computed efficiently from the transcriptome and sequencing data, then the \ambiggraph can be constructed efficiently in terms of time and space.

\subsection{Processing and Partitioning the Mapping Ambiguity Graph}
\label{sec:mag_filter}

Once the \ambiggraph $G$ is constructed, it is filtered, as described below, to yield a graph $G'$.  $G'$ is then clustered using an off-the-shelf graph clustering algorithm.  Currently, \rapclust employs two simple filters. The first filter removes nodes from $G$ that have fewer than some nominal threshold of read support over all samples in an experiment. We adopt the cutoff used by~\citep{corset}, and remove any contig with $10$ or fewer mapped reads from the \ambiggraph.  

The second filter, also inspired from~\citep{corset}, is used to remove edges between pairs of contigs that are likely to arise from paralogous genes.  Specifically, this filter tests the hypothesis that the constant of proportionality between the number of reads mapping to $t_i$ and $t_j$ does not vary (by a statistically significant amount) across conditions. 

This is done by testing the hypothesis ($H_0$) that the constant of proportionality remains constant across conditions versus the hypothesis  ($H_1$) that it does not. The log-likelihoods of the competing hypotheses $H_0$ and $H_1$ are computed according to ~\eref{eqn:likelihood_null} and \eref{eqn:likelihood_alt} respectively. A likelihood ratio test is performed, and edges $\{t_i, t_j\}$ from $G$ where $2 \left(\ell_1 - \ell_0\right) > 20$ are removed (we refer the reader to~\citep{corset} for a justification of the cutoff used in the likelihood ratio test).  This test, of course, makes some simplifying assumptions, since isoforms of the same gene might exhibit behavior consistent with $H_1$ (e.g. if isoform switching occurs between conditions).  However, we found that this filter correctly separates transcripts from paralogous genes more often than it incorrectly separates transcripts of the same gene.  Thus, applying this filter leads to a slight increase in \rapclust's precision and a typically smaller decrease in its recall.

\begin{equation}
\ell_0 = \sum_{c} \left[\left(X_i^{c} \cdot \log\left(r_{ij} \mu_j^{c}\right)\right) - \left(r_{ij} \mu_j^{c}\right)\right] + \left[\left(X_i^{c} \cdot \log\left(\mu_j^{c}\right)\right) - \left(\mu_j^{c}\right)\right]
\label{eqn:likelihood_null}
\end{equation}
\begin{equation}
\ell_1 = \sum_{c} \left[\left(X_i^{c} \cdot \log\left(r_{ij}^{c} X_j^{c}\right)\right) - \left(r_{ij}^{c} X_j^{c}\right)\right] + \left[\left(X_i^{c} \cdot \log\left(X_j^{c}\right)\right) - \left(X_j^{c}\right)\right]
\label{eqn:likelihood_alt}
\end{equation}

where

$$r_{ij}^{c} = \frac{X_i^{c}}{X_j^{c}},\; r_{ij} = \frac{\sum_{c}X_i^{c}}{\sum_{c}X_j^{c}},\; \text{ and } \mu_{j}^{c} = \frac{X_{i}^{c} + X_{j}^{c}}{1 + r_{ij}},$$

and $X_i^{c}$ denotes the number of reads mapping to contig $i$ under the $j^{\text{th}}$ condition (summed over all replicates of a condition for simplicity).

After applying both of these filters in sequence, we obtain the final processed graph $G'$, which is then clustered using \mcl~\cite{mcl}.  For the sake of simplicity, and to avoid an unnecessary dependence on parameters, we generated all the clusterings in this paper using \mcl's default parameters, and applying no additional cutoff or modification to the edge weights. 


\section{Results}
To analyze the performance of \rapclust, we have benchmarked its running time, space usage, and accuracy against \corset~\citep{corset} and \cdhit~\citep{cdhit,cdhit2} (here, we consider \cdhit\texttt{-EST}). Note that \cdhit does not provide any quantification results.  Therefore, in~\sref{subsec:DGE}, we considered the clustering computed by \cdhit, but estimated the expression of those clusters by aggregating the contig-level expression estimates computed by \sailfish.  Testing was performed on 3 datasets, human primary lung fibroblast samples, with and without a small interfering RNA (siRNA) knock down of HOXA1~\citep{humandata} (Gene Expression Omnibus accession GSE37704), yeast grown under batch and chemostat conditions~\citep{yeastdata} (Sequence Read Archive (SRA) accessions SRR453566 to SRR453571) and male and female chicken embryonic tissue~\citep{chickendata} (SRA accession SRA055442). For each of these data sets, we performed clustering of Trinity~\citep{trinity} \denovo assemblies, which were obtained from~\citep{corset_data}.

All experiments were performed on a 64-bit Linux server, running Ubuntu 14.04, with 4 hexacore Intel Xeon E5-4607 v2 CPUs (with hyper-threading) running at 2.60GHz and 256GB of RAM. Wall-clock time was recorded using the Unix \texttt{time} command. \tref{tab:data} gives a brief description of the input data.

\begin{table}[ht!]
\centering
\caption{\label{tab:data}Summary statistics for the transcriptomes and experimental samples on which the experiments were carried out, as well as the average number of fragment equivalence classes and the size of the resulting \ambiggraph.}
\begin{tabular}{lrrr}
\toprule
{} & Yeast & Human & Chicken \\
\midrule
\# contigs        &  \num{7353}  &  \num{107389} & \num{335377}  \\
\# samples        &  6  &  6 & 8  \\
Total (paired-end) reads       &  $\sim$\num{36000000}  & $\sim$\num{116000000} & $\sim$\num{181402780}  \\
Avg \# eq. classes (across samples) & \num{5197}            & \num{100535}          & \num{222216} \\
\# edges in \ambiggraph &    \num{6195}                     & \num{212481}         & \num{2063524} \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Time and Space Requirements}

Here, we report, for each clustering method, the time required to perform the clustering as well as the total size of the intermediate and result files written to disk.  It is important to note that, unlike \rapclust and \corset, \cdhit neither counts reads nor performs quantification. In order to use the clusters resulting from \cdhit in a typical analysis (e.g. quantification and differential expression testing), one would need to either align reads to the \cdhit clusters, or perform quantification on these clusters using the sequenced reads, both of which would add to the time and disk space required.

\begin{table}
\centering
\caption{\label{tab:time_space}\rapclust is \textit{substantially} faster than \corset, and requires only a small fraction of the intermediate disk space used by \corset.  The majority of space savings for \rapclust come as a result of avoiding alignment and generation of the intermediate \texttt{BAM} files. In addition to that, the percentage of reads mapped using \rapclust is much higher. Originally, the percentage of mapped reads for \rapclust was even higher than what is reported here, but we subsequently modified our default behavior to discard orphan mappings to be consistent with the behavior of the alignments provided to \corset.} %Discarding a smaller amount of data, hence, results in a greater number of clusters.}
\hskip-0.35in
\begin{tabulary}{1cm}{lrr|rr|rr}
\toprule
{} & \multicolumn{2}{c}{Yeast} & \multicolumn{2}{c}{Human} & \multicolumn{2}{c}{Chicken} \\
\midrule
{} &  \rapclust & \corset & \rapclust & \corset & \rapclust & \corset \\
\midrule
Time(min)        &  5.12  & 37.25 & 22.67  &211.67 & 64.18  &  453 \\
Space(Gb)        &  0.005  &  5.7   & 0.092  &  22   & 0.49    &  145   \\
$\%$ of reads    &  88.17    &  62.32   & 93.04    & 77.94   &  88.80   &  60.99\\
%Clusters        &  4071  &  4145 & xx   &  52575 & 69107 & xx   &  204189 & 181333 & xx\\
\bottomrule
\end{tabulary}
\end{table}

For each transcriptome, the time reported for \corset is the sum of the time required to trim the reads using \trimmomatic~\citep{trimmomatic}, align the reads using \Bowtie, and cluster the contigs using the resulting \texttt{BAM} files (this adopts the protocol and parameters suggested in the \corset documentation).  For \rapclust, the time reported is the time required to run \sailfish (v0.9.1) on all the samples, plus the time required to generate, filter and cluster the \ambiggraph.  \sailfish is run with the \texttt{--dumpEq} option to write to disk the equivalence classes computed during the quantification of each sample.  \trimmomatic, \Bowtie, and \sailfish were each run with $4$ threads.  For \cdhit, only the time required to run \cdhit is reported.  To determine the disk space required for analysis of each transcriptome using \corset, we sum the size of the \texttt{BAM} files produced by \Bowtie and the ``count'' and ``cluster'' files produced by \corset.  For \rapclust, we determined the required intermediate disk space by summing the sizes of the \sailfish quantification directories and the ``graph'' and ``cluster'' files.  Since both methods require the same input in terms of the assembled transcriptome and set of reads, we don't count these toward the space requirements.  The complete timing results (from assembly and raw reads to computed clusters) for \rapclust and \corset are presented in~\tref{tab:time_space}.  The times required for \textit{just} the clustering steps of \rapclust and \corset, as well as the time required by \cdhit, are reported in~\tref{tab:time_space_2}.  We choose to report these results separately to highlight the fact that, since \cdhit only performs clustering, if one wishes to carry out expression analysis on the clusters computed by \cdhit, she would additionally have to either align the sequenced fragments or perform contig-level abundance estimation on the samples, which could take much longer.

\begin{table}
\centering
\caption{\label{tab:time_space_2}The overall time taken for \corset and \rapclust are dominated by the time taken for alignment and quantification respectively. However, when we consider just the time required for clustering (i.e. after alignments have been generated for \corset and after the fragment equivalence classes have been generated for \rapclust), we observe that \rapclust and \cdhit are considerably faster than \corset.  As \corset's clustering phase is single-threaded, we provide times for all methods in this table using only a single thread. (RC = \rapclust, CD = \cdhit, CT = \corset)}
\begin{tabulary}{1cm}{lrrr|rrr|rrr}
\toprule
{} & \multicolumn{3}{c}{Yeast} & \multicolumn{3}{c}{Human} & \multicolumn{3}{c}{Chicken} \\
\midrule
{} &  RC & CD & CT &  RC & CD & CT & RC & CD & CT \\
\midrule

Time(min)        &  0.04  & 0.2  & 2.8 &  0.82 & 4.02 & 16.25 &   5.29  &  36.5 & 87\\
\bottomrule
\end{tabulary}
\end{table}

\subsection{Assessing Cluster Quality}
\label{subsec:quality}
\begin{figure}[htb]
    \centering
    \subcaptionbox{Accuracy for yeast\label{fig:concordance_yeast}}[0.3\textwidth]{
        \includegraphics[width=0.3\textwidth]{Figures/concordance_yeast_legend}}
    \subcaptionbox{Accuracy for human\label{fig:concordance_human}}[0.3\textwidth]{
        \includegraphics[width=0.3\textwidth]{Figures/concordance_human}}
    \subcaptionbox{Accuracy for chicken\label{fig:concordance_chicken}}[0.3\textwidth]{
        \includegraphics[width=0.3\textwidth]{Figures/concordance_chicken}}
    \caption{The precision, recall, and F1-score of the \rapclust, \corset and \cdhit based clusterings, with respect to ground-truth annotations, on the yeast a, human b and chicken c data sets.\label{fig:cluster_quality}}
\end{figure}

We assessed the quality of the clusters obtained by the various tools using two different metrics. The ground truth labels for \denovo assembled contigs were taken from~\citep{corset_data}, and the process of obtaining these labels is described in~\citep{corset}.  It is important to note that not all contigs can be labeled with an annotated gene, and unlabeled contigs were omitted when computing the metrics below.


First, we considered the precision and recall metrics used by~\citet{corset}.  Here, pairs of contigs are classified based on whether their cluster labels match their annotated gene labels.  Specifically, a pair of contigs labeled with the same gene is considered a true-positive (TP) if the pair is co-clustered and a false-negative (FN) if the contigs are placed in separate clusters.  Likewise, if a pair of contigs labeled with different genes is placed into the same cluster, it is considered a false-positive (FP) and if they are placed in different clusters, it is considered a true-negative (TN).  From these pairwise counts, the precision and recall can be computed as $\text{Precision} = \nicefrac{\text{TP}}{\text{TP}+\text{FP}}$ and $\text{Recall} = \nicefrac{\text{TP}}{\text{TP}+\text{FN}}$.  A higher precision signifies that, when contigs are co-clustered, they are more likely to have originated from the same underlying gene.  A higher recall, on the other hand, suggests that more contigs originating from the same gene tend to be co-clustered.  Typically, precision and recall are competing objectives, as \textit{over clustering} will improve recall but harm precision while \textit{under clustering} will improve precision but harm recall.  Commonly, the $\text{F1-Score} = 2 \left(\nicefrac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}\right)$ is used as a single metric to summarize performance in terms of both the precision and recall. \fref{fig:cluster_quality} shows the accuracy of all three tools on the three assemblies in terms of Precision, Recall and F1-Score.  \corset and \rapclust generate similar clusters, with \rapclust generally yielding slightly higher recall than \corset.  \cdhit, however, tends to do a much poorer job at trading off between these competing objectives.  It provides similar (or, in case of the yeast data, higher) precision to \corset and \rapclust, but the resulting clusters exhibit much lower recall.

Second, we considered how similar the clusters obtained using the different methods are to the ground truth clustering, which groups together all contigs labeled with the same gene.  To assess this similarity, we used the variation of information (VI)~\citep{vi}. The VI is defined over a pair of clusterings, and quantifies the information lost and gained when moving from one clustering to the other.  It allows one to measure how similar two clusterings are, regardless of the specific names or labels chosen for the clusters.  The lower the VI between a pair of clusters, the more similar they are.  To compute the VI between the true clustering $C_T$ and that obtained by a particular method $C_M$, we discarded all contigs in $C_M$ that are not labeled with a gene name, while retaining the clustering relations among the remaining contigs.  If any contigs that correspond to annotated genes do not exist in $C_M$ (since they may be discarded, e.g., by the read count filter described in~\sref{sec:mag_filter}), we considered them to come from a single cluster, which is given a new label.  We called the resulting clustering $C_{M'}$. Hence, $C_T$ and $C_{M'}$ are defined over the same set of contigs, and the similarity between them can be computed directly using the VI.  The VI results are presented in~\Cref{tab:VI}.  \rapclust and \corset seem to yield similar results, with \rapclust obtaining a slightly lower (better) VI. However, we observed a \textit{marked} difference between these two and \cdhit, whose clusters exhibit a substantially larger VI, especially on the human and chicken data.

\begin{table}
\caption{\label{tab:VI}The variation of information between contig to gene mapping using genome-based mapping approach and the clusters generated using \rapclust, \corset and \cdhit.  For each assembly, the clustering producing the lowest variation of information with respect to the true clustering is set in bold; \rapclust achieves the lowest VI on all assemblies.}
\centering
\begin{tabular}{cccc}
  \toprule
  & \rapclust & \corset & \cdhit \\
  \midrule
  Chicken & \textbf{0.127} & 0.191 & 2.01 \\
  Human & \textbf{0.712} & 0.735 & 1.24 \\
  Yeast & \textbf{0.176} & 0.178 & 0.216 \\
  %Chicken & \cellcolor{green}0.145 & \cellcolor{yellow}0.191 & 0.0 \\
  %\hline
  %Human & \cellcolor{green}0.712 & \cellcolor{yellow}0.735 & \cellcolor{red}0.881 \\ 
  %\hline
  %Yeast & \cellcolor{green}0.176 & \cellcolor{yellow}0.178 & \cellcolor{red}0.2 \\
  \bottomrule
\end{tabular}
\end{table}

\subsection{Differential Gene Expression}
\label{subsec:DGE}
We also tested the ability to recover gene-level differential expression using the clusterings produced by the different methods. \Denovo transcriptome assemblers have a tendency to produce many (often fractured) contigs. This tends to confound downstream differential expression analyses, due, in part, to the difficulty of quantifying fractured or incorrectly assembled contigs, and due, in part, to the potentially large number of extra statistical tests being performed (that must be corrected for). By estimating expression, and performing differential expression testing at the cluster level, one might expect to simultaneously reduce the multiple hypothesis testing burden and ``average out'' some of the mistakes made in contig-level abundance estimation.

For gene-level differential expression analysis, we compared the genes called as differentially expressed under each of the different clusterings versus the genes detected as differentially expressed under the true contig-to-gene mapping (again, note that not all contigs are annotated with a gene label). We generated ``ground truth'' gene-level abundance estimates based on the contig-level abundance estimates computed by \sailfish, and the true contig-to-gene mapping.  Using the tximport~\citep{tximport} R package, we loaded the \sailfish expression estimates, aggregated them to the gene level, and prepared them for use with DEseq2~\citep{deseq2}.  A 2-condition differential expression test was performed in each data set; for human this was in between the conditions with and without the HOX1A knockdown, for yeast it was in the batch and chemostat growth conditions, and for chicken it was in the male and female samples (we collapsed the different tissues within each sex). We then obtained corrected p-values for the hypothesis that each gene is differentially expressed across the conditions we considered. We considered genes having a corrected p-value less than or equal to $0.05$ as differentially expressed. We estimated differential expression under the \rapclust and \cdhit clusterings in the same manner, where the quantification estimates were held fixed, but the true contig-to-gene mapping was replaced with the contig-to-cluster mapping produced by these tools.  For \corset, a count matrix is directly provided that was used as input to DESeq2.

As a metric of comparison, we examined the rate at which true positive differentially expressed genes were recovered versus the rate at which false positive differentially expressed genes were called. Each predicted cluster was labeled with the union of all of the genes with which its constituent contigs were labeled. We sorted the list of clusters by p-value, and processed them in the following manner: when we encountered a cluster, we intersected its set of labeled genes with the set of truly differentially expressed genes. Any genes that had not already been encountered in a more highly-ranked cluster were considered as true positive predictions. Likewise, any genes that appeared in the cluster, but which did not occur in the true set of differentially expressed genes were considered as false positives (if the genes had not already been encountered in a more highly-ranked cluster). We stopped processing the clusters once their adjusted p-value exceeded $0.05$ (since, under common threshold, such clusters would likely not be considered to be differentially expressed). For the true and false positive predictions we encountered, the associated negative p-value of the associated cluster was used as the corresponding ``score''. The ROC curves were generated using the CROC~\cite{croc} Python package.

\begin{figure}[thb!]
    \centering
    \subcaptionbox*{Yeast\label{fig:dge_yeast}}[0.3\textwidth]{
        \includegraphics[width=0.3\textwidth]{Figures/yeast_dge_curves}}
    \subcaptionbox*{Human\label{fig:dge_human}}[0.3\textwidth]{
        \includegraphics[width=0.3\textwidth]{Figures/human_dge_curves}}
    \subcaptionbox*{Chicken\label{fig:dge_chicken}}[0.3\textwidth]{
        \includegraphics[width=0.3\textwidth]{Figures/chicken_dge_curves}}
    \caption{ROC curves showing the recovery rate of \rapclust, \corset, and \cdhit's clusters in recovering 
        differentially expressed genes in each data set.\label{fig:ROC}}
\end{figure}

Overall, poor precision or recall in terms of clustering may lead to detection of fewer truly differentially expressed genes, spurious identification of differential expression, or weak statistical evidence for differential expression.~\fref{fig:ROC} shows that the rate at which \rapclust recovers true positives versus false positives is higher than that of \cdhit in $2$ of the $3$ assemblies, and is higher than that of \corset in all the assemblies, as represented by the respective area under the curves. The benefit of \rapclust is particularly apparent in the chicken assembly. Since the quantification results produced by \sailfish tend to be reasonable, even when the clustering is fairly poor, this may explain the relatively good performance of the \cdhit clustering in yeast (relative to the rather poor quality of the clustering, as evaluated in~\Cref{subsec:quality}).

